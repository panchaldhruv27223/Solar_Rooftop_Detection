{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import datetime, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/student/Documents/Arpit_sir/SOLAR/CodeFiles/dhruv_git/Solar_Rooftop_Detection/Solar_Rooftop_Detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images are: 2880\n"
     ]
    }
   ],
   "source": [
    "### create image path lists\n",
    "## images folder \n",
    "images_path = os.path.join(os.getcwd(),\"Arial_images_1024_1024/images\")\n",
    "print(f\"number of images are: {len(os.listdir(images_path))}\")\n",
    "\n",
    "## creating images list in which we are storing our images path\n",
    "images = []\n",
    "\n",
    "# for i in range(len(os.listdir(images_path))):\n",
    "for i in range(10):\n",
    "    images.append(f\"{os.path.join(images_path,os.listdir(images_path)[i])}\")\n",
    "\n",
    "\n",
    "# print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = images[0]\n",
    "im = cv2.imread(img_1)\n",
    "\n",
    "cv2.imshow(\"Demo-Image\",im)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of masks are: 2880\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "## the same way lets create list of masks\n",
    "masks_path = os.path.join(os.getcwd(),\"Arial_images_1024_1024/masks\")\n",
    "print(f\"number of masks are: {len(os.listdir(masks_path))}\")\n",
    "\n",
    "## creating masks list in which we are storing our masks path\n",
    "masks = []\n",
    "\n",
    "# for i in range(len(os.listdir(masks_path))):\n",
    "for i in range(10):\n",
    "    masks.append(f\"{os.path.join(masks_path,os.listdir(masks_path)[i])}\")\n",
    "\n",
    "print(len(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/student/Documents/Arpit_sir/SOLAR/CodeFiles/dhruv_git/Solar_Rooftop_Detection'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitignore',\n",
       " 'Solar_Rooftop_Detection',\n",
       " 'sam_vit_b.pth',\n",
       " 'ReadMe.MD',\n",
       " 'logs',\n",
       " 'test.ipynb',\n",
       " 'Arial_images_1024_1024',\n",
       " 'trial.ipynb',\n",
       " 'checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Solar_Rooftop_Detection.get_bounding_box_cordinates import bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SAM_logger.py - 17-Feb-2025 20:56:18 - INFO - <module> - Line 25 - SAM model Logger has been started.\n"
     ]
    }
   ],
   "source": [
    "from Solar_Rooftop_Detection.SAM_logger import sam_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2265001132.py - 17-Feb-2025 20:56:18 - INFO - <module> - Line 1 - SAM Logger initialized\n"
     ]
    }
   ],
   "source": [
    "sam_logger.info(\"SAM Logger initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this dictionary contain image_path as key and as vlaues it store the list of bounding box cordinates.\n",
    "bounding_boxes = {}\n",
    "\n",
    "for i in range(len(images)):\n",
    "    mask_img = cv2.imread(masks[i], cv2.IMREAD_GRAYSCALE)\n",
    "    bounding_boxes[images[i]] = bounding_box(mask_img)\n",
    "\n",
    "# print(len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now create custom Datset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class my_dataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        \n",
    "        # Convert image to RGB format\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        ## Load and preprocess the binary mask(1 channel)\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (1024,1024))\n",
    "\n",
    "        ## Convert image and mask to torch tensor \n",
    "        image = torch.tensor(image).permute(2,0,1).float()/255.0\n",
    "        mask = torch.tensor(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = my_dataset(images, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x716c8165df90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now implement Data Loader\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=2, shuffle=True)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import build_sam_vit_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run only when you dont have vit-b model in you local machine\n",
    "# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -O sam_vit_b.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/Documents/Arpit_sir/solar_vnv/lib/python3.10/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sam(\n",
       "  (image_encoder): ImageEncoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initiallize the SAM model with vit-b configuration\n",
    "model = build_sam_vit_b(\"/home/student/Documents/Arpit_sir/SOLAR/CodeFiles/dhruv_git/Solar_Rooftop_Detection/sam_vit_b.pth\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sam(\n",
       "  (image_encoder): ImageEncoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## select device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the optimizer and the loss function\n",
    "optimizer = Adam(model.mask_decoder.parameters(), lr=1e-5, weight_decay=0)\n",
    "#Try DiceFocalLoss, FocalLoss, DiceCELoss\n",
    "seg_loss = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Solar_Rooftop_Detection.generate_isolated_masks import generate_isolated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of Sam(\n",
       "  (image_encoder): ImageEncoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we only compute gradients for mask decoder\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"image_encoder\") or name.startswith(\"prompt_encoder\"):\n",
    "        param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"checkpoints\"\n",
    "os.makedirs(checkpoint, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0001):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait before stopping if no improvement.\n",
    "            min_delta (float): Minimum change in loss to be considered as improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model, epoch):\n",
    "        \"\"\"Checks validation loss and determines if training should stop.\"\"\"\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0  # Reset counter if improvement occurs\n",
    "\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"No improvement for {self.counter}/{self.patience} epochs...\")\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1470904569.py - 17-Feb-2025 20:56:19 - INFO - <module> - Line 1 - Training Started\n",
      "1470904569.py - 17-Feb-2025 20:56:19 - INFO - <module> - Line 5 - Epoch 1/20 started\n",
      "1470904569.py - 17-Feb-2025 20:56:19 - INFO - <module> - Line 24 - Bounding Box Coordinates: 0\n",
      "1470904569.py - 17-Feb-2025 20:56:19 - INFO - <module> - Line 24 - Bounding Box Coordinates: 4\n",
      "1470904569.py - 17-Feb-2025 20:56:24 - INFO - <module> - Line 74 - Current running loss: 0.0123\n",
      "1470904569.py - 17-Feb-2025 20:56:28 - INFO - <module> - Line 74 - Current running loss: 0.0426\n",
      "1470904569.py - 17-Feb-2025 20:56:33 - INFO - <module> - Line 74 - Current running loss: 0.0747\n",
      "1470904569.py - 17-Feb-2025 20:56:38 - INFO - <module> - Line 74 - Current running loss: 0.1318\n",
      "1470904569.py - 17-Feb-2025 20:56:38 - INFO - <module> - Line 24 - Bounding Box Coordinates: 2\n",
      "1470904569.py - 17-Feb-2025 20:56:42 - INFO - <module> - Line 74 - Current running loss: 0.2378\n",
      "1470904569.py - 17-Feb-2025 20:56:46 - INFO - <module> - Line 74 - Current running loss: 0.2994\n",
      "1470904569.py - 17-Feb-2025 20:56:46 - INFO - <module> - Line 24 - Bounding Box Coordinates: 33\n",
      "1470904569.py - 17-Feb-2025 20:56:51 - INFO - <module> - Line 74 - Current running loss: 0.3014\n",
      "1470904569.py - 17-Feb-2025 20:56:55 - INFO - <module> - Line 74 - Current running loss: 0.3031\n",
      "1470904569.py - 17-Feb-2025 20:57:00 - INFO - <module> - Line 74 - Current running loss: 0.3039\n",
      "1470904569.py - 17-Feb-2025 20:57:04 - INFO - <module> - Line 74 - Current running loss: 0.3090\n",
      "1470904569.py - 17-Feb-2025 20:57:09 - INFO - <module> - Line 74 - Current running loss: 0.3156\n",
      "1470904569.py - 17-Feb-2025 20:57:13 - INFO - <module> - Line 74 - Current running loss: 0.3250\n",
      "1470904569.py - 17-Feb-2025 20:57:17 - INFO - <module> - Line 74 - Current running loss: 0.3272\n",
      "1470904569.py - 17-Feb-2025 20:57:22 - INFO - <module> - Line 74 - Current running loss: 0.3329\n",
      "1470904569.py - 17-Feb-2025 20:57:26 - INFO - <module> - Line 74 - Current running loss: 0.3340\n",
      "1470904569.py - 17-Feb-2025 20:57:31 - INFO - <module> - Line 74 - Current running loss: 0.3372\n",
      "1470904569.py - 17-Feb-2025 20:57:35 - INFO - <module> - Line 74 - Current running loss: 0.3481\n",
      "1470904569.py - 17-Feb-2025 20:57:40 - INFO - <module> - Line 74 - Current running loss: 0.3502\n",
      "1470904569.py - 17-Feb-2025 20:57:44 - INFO - <module> - Line 74 - Current running loss: 0.3516\n",
      "1470904569.py - 17-Feb-2025 20:57:49 - INFO - <module> - Line 74 - Current running loss: 0.3522\n",
      "1470904569.py - 17-Feb-2025 20:57:53 - INFO - <module> - Line 74 - Current running loss: 0.3535\n",
      "1470904569.py - 17-Feb-2025 20:57:58 - INFO - <module> - Line 74 - Current running loss: 0.3577\n",
      "1470904569.py - 17-Feb-2025 20:58:02 - INFO - <module> - Line 74 - Current running loss: 0.3578\n",
      "1470904569.py - 17-Feb-2025 20:58:07 - INFO - <module> - Line 74 - Current running loss: 0.3581\n",
      "1470904569.py - 17-Feb-2025 20:58:12 - INFO - <module> - Line 74 - Current running loss: 0.3707\n",
      "1470904569.py - 17-Feb-2025 20:58:16 - INFO - <module> - Line 74 - Current running loss: 0.3718\n",
      "1470904569.py - 17-Feb-2025 20:58:21 - INFO - <module> - Line 74 - Current running loss: 0.3774\n",
      "1470904569.py - 17-Feb-2025 20:58:25 - INFO - <module> - Line 74 - Current running loss: 0.3781\n",
      "1470904569.py - 17-Feb-2025 20:58:30 - INFO - <module> - Line 74 - Current running loss: 0.3797\n",
      "1470904569.py - 17-Feb-2025 20:58:34 - INFO - <module> - Line 74 - Current running loss: 0.3818\n",
      "1470904569.py - 17-Feb-2025 20:58:39 - INFO - <module> - Line 74 - Current running loss: 0.3856\n",
      "1470904569.py - 17-Feb-2025 20:58:43 - INFO - <module> - Line 74 - Current running loss: 0.3865\n",
      "1470904569.py - 17-Feb-2025 20:58:48 - INFO - <module> - Line 74 - Current running loss: 0.3876\n",
      "1470904569.py - 17-Feb-2025 20:58:52 - INFO - <module> - Line 74 - Current running loss: 0.3907\n",
      "1470904569.py - 17-Feb-2025 20:58:57 - INFO - <module> - Line 74 - Current running loss: 0.3923\n",
      "1470904569.py - 17-Feb-2025 20:59:01 - INFO - <module> - Line 74 - Current running loss: 0.3937\n",
      "1470904569.py - 17-Feb-2025 20:59:06 - INFO - <module> - Line 74 - Current running loss: 0.3954\n",
      "1470904569.py - 17-Feb-2025 20:59:10 - INFO - <module> - Line 74 - Current running loss: 0.4029\n",
      "1470904569.py - 17-Feb-2025 20:59:14 - INFO - <module> - Line 74 - Current running loss: 0.4064\n",
      "1470904569.py - 17-Feb-2025 20:59:15 - INFO - <module> - Line 24 - Bounding Box Coordinates: 7\n",
      "1470904569.py - 17-Feb-2025 20:59:19 - INFO - <module> - Line 74 - Current running loss: 0.5459\n",
      "1470904569.py - 17-Feb-2025 20:59:23 - INFO - <module> - Line 74 - Current running loss: 0.5958\n",
      "1470904569.py - 17-Feb-2025 20:59:28 - INFO - <module> - Line 74 - Current running loss: 0.6109\n",
      "1470904569.py - 17-Feb-2025 20:59:33 - INFO - <module> - Line 74 - Current running loss: 0.6182\n",
      "1470904569.py - 17-Feb-2025 20:59:37 - INFO - <module> - Line 74 - Current running loss: 0.6358\n",
      "1470904569.py - 17-Feb-2025 20:59:41 - INFO - <module> - Line 74 - Current running loss: 0.6492\n",
      "1470904569.py - 17-Feb-2025 20:59:46 - INFO - <module> - Line 74 - Current running loss: 0.6607\n",
      "1470904569.py - 17-Feb-2025 20:59:46 - INFO - <module> - Line 24 - Bounding Box Coordinates: 89\n",
      "1470904569.py - 17-Feb-2025 20:59:51 - INFO - <module> - Line 74 - Current running loss: 0.6669\n",
      "1470904569.py - 17-Feb-2025 20:59:56 - INFO - <module> - Line 74 - Current running loss: 0.6682\n",
      "1470904569.py - 17-Feb-2025 21:00:00 - INFO - <module> - Line 74 - Current running loss: 0.6699\n",
      "1470904569.py - 17-Feb-2025 21:00:05 - INFO - <module> - Line 74 - Current running loss: 0.6717\n",
      "1470904569.py - 17-Feb-2025 21:00:09 - INFO - <module> - Line 74 - Current running loss: 0.6764\n",
      "1470904569.py - 17-Feb-2025 21:00:14 - INFO - <module> - Line 74 - Current running loss: 0.6775\n",
      "1470904569.py - 17-Feb-2025 21:00:18 - INFO - <module> - Line 74 - Current running loss: 0.6808\n",
      "1470904569.py - 17-Feb-2025 21:00:23 - INFO - <module> - Line 74 - Current running loss: 0.6897\n",
      "1470904569.py - 17-Feb-2025 21:00:28 - INFO - <module> - Line 74 - Current running loss: 0.6920\n",
      "1470904569.py - 17-Feb-2025 21:00:32 - INFO - <module> - Line 74 - Current running loss: 0.6926\n",
      "1470904569.py - 17-Feb-2025 21:00:37 - INFO - <module> - Line 74 - Current running loss: 0.7014\n",
      "1470904569.py - 17-Feb-2025 21:00:41 - INFO - <module> - Line 74 - Current running loss: 0.7025\n",
      "1470904569.py - 17-Feb-2025 21:00:46 - INFO - <module> - Line 74 - Current running loss: 0.7049\n",
      "1470904569.py - 17-Feb-2025 21:00:50 - INFO - <module> - Line 74 - Current running loss: 0.7062\n",
      "1470904569.py - 17-Feb-2025 21:00:55 - INFO - <module> - Line 74 - Current running loss: 0.7076\n",
      "1470904569.py - 17-Feb-2025 21:00:59 - INFO - <module> - Line 74 - Current running loss: 0.7091\n",
      "1470904569.py - 17-Feb-2025 21:01:03 - INFO - <module> - Line 74 - Current running loss: 0.7109\n",
      "1470904569.py - 17-Feb-2025 21:01:08 - INFO - <module> - Line 74 - Current running loss: 0.7120\n",
      "1470904569.py - 17-Feb-2025 21:01:13 - INFO - <module> - Line 74 - Current running loss: 0.7164\n",
      "1470904569.py - 17-Feb-2025 21:01:17 - INFO - <module> - Line 74 - Current running loss: 0.7184\n",
      "1470904569.py - 17-Feb-2025 21:01:22 - INFO - <module> - Line 74 - Current running loss: 0.7197\n",
      "1470904569.py - 17-Feb-2025 21:01:26 - INFO - <module> - Line 74 - Current running loss: 0.7210\n",
      "1470904569.py - 17-Feb-2025 21:01:31 - INFO - <module> - Line 74 - Current running loss: 0.7231\n",
      "1470904569.py - 17-Feb-2025 21:01:36 - INFO - <module> - Line 74 - Current running loss: 0.7244\n",
      "1470904569.py - 17-Feb-2025 21:01:40 - INFO - <module> - Line 74 - Current running loss: 0.7261\n",
      "1470904569.py - 17-Feb-2025 21:01:45 - INFO - <module> - Line 74 - Current running loss: 0.7275\n",
      "1470904569.py - 17-Feb-2025 21:01:49 - INFO - <module> - Line 74 - Current running loss: 0.7301\n",
      "1470904569.py - 17-Feb-2025 21:01:54 - INFO - <module> - Line 74 - Current running loss: 0.7313\n",
      "1470904569.py - 17-Feb-2025 21:01:59 - INFO - <module> - Line 74 - Current running loss: 0.7323\n",
      "1470904569.py - 17-Feb-2025 21:02:03 - INFO - <module> - Line 74 - Current running loss: 0.7338\n",
      "1470904569.py - 17-Feb-2025 21:02:08 - INFO - <module> - Line 74 - Current running loss: 0.7346\n",
      "1470904569.py - 17-Feb-2025 21:02:12 - INFO - <module> - Line 74 - Current running loss: 0.7368\n",
      "1470904569.py - 17-Feb-2025 21:02:17 - INFO - <module> - Line 74 - Current running loss: 0.7385\n",
      "1470904569.py - 17-Feb-2025 21:02:22 - INFO - <module> - Line 74 - Current running loss: 0.7396\n",
      "1470904569.py - 17-Feb-2025 21:02:26 - INFO - <module> - Line 74 - Current running loss: 0.7417\n",
      "1470904569.py - 17-Feb-2025 21:02:31 - INFO - <module> - Line 74 - Current running loss: 0.7438\n",
      "1470904569.py - 17-Feb-2025 21:02:35 - INFO - <module> - Line 74 - Current running loss: 0.7451\n",
      "1470904569.py - 17-Feb-2025 21:02:40 - INFO - <module> - Line 74 - Current running loss: 0.7474\n",
      "1470904569.py - 17-Feb-2025 21:02:44 - INFO - <module> - Line 74 - Current running loss: 0.7512\n",
      "1470904569.py - 17-Feb-2025 21:02:49 - INFO - <module> - Line 74 - Current running loss: 0.7530\n",
      "1470904569.py - 17-Feb-2025 21:02:53 - INFO - <module> - Line 74 - Current running loss: 0.7539\n",
      "1470904569.py - 17-Feb-2025 21:02:58 - INFO - <module> - Line 74 - Current running loss: 0.7564\n",
      "1470904569.py - 17-Feb-2025 21:03:02 - INFO - <module> - Line 74 - Current running loss: 0.7578\n",
      "1470904569.py - 17-Feb-2025 21:03:07 - INFO - <module> - Line 74 - Current running loss: 0.7598\n",
      "1470904569.py - 17-Feb-2025 21:03:11 - INFO - <module> - Line 74 - Current running loss: 0.7613\n",
      "1470904569.py - 17-Feb-2025 21:03:16 - INFO - <module> - Line 74 - Current running loss: 0.7633\n",
      "1470904569.py - 17-Feb-2025 21:03:20 - INFO - <module> - Line 74 - Current running loss: 0.7645\n",
      "1470904569.py - 17-Feb-2025 21:03:25 - INFO - <module> - Line 74 - Current running loss: 0.7652\n",
      "1470904569.py - 17-Feb-2025 21:03:30 - INFO - <module> - Line 74 - Current running loss: 0.7668\n",
      "1470904569.py - 17-Feb-2025 21:03:35 - INFO - <module> - Line 74 - Current running loss: 0.7681\n",
      "1470904569.py - 17-Feb-2025 21:03:39 - INFO - <module> - Line 74 - Current running loss: 0.7695\n",
      "1470904569.py - 17-Feb-2025 21:03:44 - INFO - <module> - Line 74 - Current running loss: 0.7712\n",
      "1470904569.py - 17-Feb-2025 21:03:49 - INFO - <module> - Line 74 - Current running loss: 0.7730\n",
      "1470904569.py - 17-Feb-2025 21:03:53 - INFO - <module> - Line 74 - Current running loss: 0.7746\n",
      "1470904569.py - 17-Feb-2025 21:03:58 - INFO - <module> - Line 74 - Current running loss: 0.7770\n",
      "1470904569.py - 17-Feb-2025 21:04:03 - INFO - <module> - Line 74 - Current running loss: 0.7790\n",
      "1470904569.py - 17-Feb-2025 21:04:07 - INFO - <module> - Line 74 - Current running loss: 0.7811\n",
      "1470904569.py - 17-Feb-2025 21:04:12 - INFO - <module> - Line 74 - Current running loss: 0.7839\n",
      "1470904569.py - 17-Feb-2025 21:04:16 - INFO - <module> - Line 74 - Current running loss: 0.7849\n",
      "1470904569.py - 17-Feb-2025 21:04:21 - INFO - <module> - Line 74 - Current running loss: 0.7862\n",
      "1470904569.py - 17-Feb-2025 21:04:25 - INFO - <module> - Line 74 - Current running loss: 0.7886\n",
      "1470904569.py - 17-Feb-2025 21:04:30 - INFO - <module> - Line 74 - Current running loss: 0.7894\n",
      "1470904569.py - 17-Feb-2025 21:04:35 - INFO - <module> - Line 74 - Current running loss: 0.7917\n",
      "1470904569.py - 17-Feb-2025 21:04:40 - INFO - <module> - Line 74 - Current running loss: 0.7935\n",
      "1470904569.py - 17-Feb-2025 21:04:44 - INFO - <module> - Line 74 - Current running loss: 0.7957\n",
      "1470904569.py - 17-Feb-2025 21:04:49 - INFO - <module> - Line 74 - Current running loss: 0.7970\n",
      "1470904569.py - 17-Feb-2025 21:04:54 - INFO - <module> - Line 74 - Current running loss: 0.7987\n",
      "1470904569.py - 17-Feb-2025 21:04:59 - INFO - <module> - Line 74 - Current running loss: 0.8015\n",
      "1470904569.py - 17-Feb-2025 21:05:04 - INFO - <module> - Line 74 - Current running loss: 0.8054\n",
      "1470904569.py - 17-Feb-2025 21:05:08 - INFO - <module> - Line 74 - Current running loss: 0.8063\n",
      "1470904569.py - 17-Feb-2025 21:05:13 - INFO - <module> - Line 74 - Current running loss: 0.8071\n",
      "1470904569.py - 17-Feb-2025 21:05:17 - INFO - <module> - Line 74 - Current running loss: 0.8096\n",
      "1470904569.py - 17-Feb-2025 21:05:22 - INFO - <module> - Line 74 - Current running loss: 0.8114\n",
      "1470904569.py - 17-Feb-2025 21:05:26 - INFO - <module> - Line 74 - Current running loss: 0.8127\n",
      "1470904569.py - 17-Feb-2025 21:05:31 - INFO - <module> - Line 74 - Current running loss: 0.8133\n",
      "1470904569.py - 17-Feb-2025 21:05:35 - INFO - <module> - Line 74 - Current running loss: 0.8159\n",
      "1470904569.py - 17-Feb-2025 21:05:40 - INFO - <module> - Line 74 - Current running loss: 0.8185\n",
      "1470904569.py - 17-Feb-2025 21:05:45 - INFO - <module> - Line 74 - Current running loss: 0.8203\n",
      "1470904569.py - 17-Feb-2025 21:05:50 - INFO - <module> - Line 74 - Current running loss: 0.8225\n",
      "1470904569.py - 17-Feb-2025 21:05:54 - INFO - <module> - Line 74 - Current running loss: 0.8237\n",
      "1470904569.py - 17-Feb-2025 21:05:59 - INFO - <module> - Line 74 - Current running loss: 0.8258\n",
      "1470904569.py - 17-Feb-2025 21:06:03 - INFO - <module> - Line 74 - Current running loss: 0.8273\n",
      "1470904569.py - 17-Feb-2025 21:06:08 - INFO - <module> - Line 74 - Current running loss: 0.8278\n",
      "1470904569.py - 17-Feb-2025 21:06:13 - INFO - <module> - Line 74 - Current running loss: 0.8300\n",
      "1470904569.py - 17-Feb-2025 21:06:17 - INFO - <module> - Line 74 - Current running loss: 0.8329\n",
      "1470904569.py - 17-Feb-2025 21:06:22 - INFO - <module> - Line 74 - Current running loss: 0.8342\n",
      "1470904569.py - 17-Feb-2025 21:06:27 - INFO - <module> - Line 74 - Current running loss: 0.8349\n",
      "1470904569.py - 17-Feb-2025 21:06:31 - INFO - <module> - Line 74 - Current running loss: 0.8358\n",
      "1470904569.py - 17-Feb-2025 21:06:36 - INFO - <module> - Line 74 - Current running loss: 0.8394\n",
      "1470904569.py - 17-Feb-2025 21:06:36 - INFO - <module> - Line 24 - Bounding Box Coordinates: 11\n",
      "1470904569.py - 17-Feb-2025 21:06:40 - INFO - <module> - Line 74 - Current running loss: 0.8480\n",
      "1470904569.py - 17-Feb-2025 21:06:45 - INFO - <module> - Line 74 - Current running loss: 0.8574\n",
      "1470904569.py - 17-Feb-2025 21:06:50 - INFO - <module> - Line 74 - Current running loss: 0.8791\n",
      "1470904569.py - 17-Feb-2025 21:06:54 - INFO - <module> - Line 74 - Current running loss: 0.8858\n",
      "1470904569.py - 17-Feb-2025 21:06:59 - INFO - <module> - Line 74 - Current running loss: 0.9066\n",
      "1470904569.py - 17-Feb-2025 21:07:03 - INFO - <module> - Line 74 - Current running loss: 0.9273\n",
      "1470904569.py - 17-Feb-2025 21:07:08 - INFO - <module> - Line 74 - Current running loss: 0.9395\n",
      "1470904569.py - 17-Feb-2025 21:07:13 - INFO - <module> - Line 74 - Current running loss: 0.9646\n",
      "1470904569.py - 17-Feb-2025 21:07:17 - INFO - <module> - Line 74 - Current running loss: 0.9698\n",
      "1470904569.py - 17-Feb-2025 21:07:22 - INFO - <module> - Line 74 - Current running loss: 0.9836\n",
      "1470904569.py - 17-Feb-2025 21:07:27 - INFO - <module> - Line 74 - Current running loss: 0.9877\n",
      "1470904569.py - 17-Feb-2025 21:07:27 - INFO - <module> - Line 24 - Bounding Box Coordinates: 77\n",
      "1470904569.py - 17-Feb-2025 21:07:31 - INFO - <module> - Line 74 - Current running loss: 0.9893\n",
      "1470904569.py - 17-Feb-2025 21:07:36 - INFO - <module> - Line 74 - Current running loss: 0.9925\n",
      "1470904569.py - 17-Feb-2025 21:07:40 - INFO - <module> - Line 74 - Current running loss: 0.9936\n",
      "1470904569.py - 17-Feb-2025 21:07:45 - INFO - <module> - Line 74 - Current running loss: 0.9949\n",
      "1470904569.py - 17-Feb-2025 21:07:49 - INFO - <module> - Line 74 - Current running loss: 0.9955\n",
      "1470904569.py - 17-Feb-2025 21:07:54 - INFO - <module> - Line 74 - Current running loss: 0.9966\n",
      "1470904569.py - 17-Feb-2025 21:07:58 - INFO - <module> - Line 74 - Current running loss: 0.9974\n",
      "1470904569.py - 17-Feb-2025 21:08:03 - INFO - <module> - Line 74 - Current running loss: 1.0013\n",
      "1470904569.py - 17-Feb-2025 21:08:08 - INFO - <module> - Line 74 - Current running loss: 1.0037\n",
      "1470904569.py - 17-Feb-2025 21:08:12 - INFO - <module> - Line 74 - Current running loss: 1.0053\n",
      "1470904569.py - 17-Feb-2025 21:08:17 - INFO - <module> - Line 74 - Current running loss: 1.0077\n",
      "1470904569.py - 17-Feb-2025 21:08:21 - INFO - <module> - Line 74 - Current running loss: 1.0113\n",
      "1470904569.py - 17-Feb-2025 21:08:26 - INFO - <module> - Line 74 - Current running loss: 1.0153\n",
      "1470904569.py - 17-Feb-2025 21:08:30 - INFO - <module> - Line 74 - Current running loss: 1.0174\n",
      "1470904569.py - 17-Feb-2025 21:08:35 - INFO - <module> - Line 74 - Current running loss: 1.0204\n",
      "1470904569.py - 17-Feb-2025 21:08:39 - INFO - <module> - Line 74 - Current running loss: 1.0216\n",
      "1470904569.py - 17-Feb-2025 21:08:44 - INFO - <module> - Line 74 - Current running loss: 1.0227\n",
      "1470904569.py - 17-Feb-2025 21:08:48 - INFO - <module> - Line 74 - Current running loss: 1.0261\n",
      "1470904569.py - 17-Feb-2025 21:08:53 - INFO - <module> - Line 74 - Current running loss: 1.0286\n",
      "1470904569.py - 17-Feb-2025 21:08:58 - INFO - <module> - Line 74 - Current running loss: 1.0301\n",
      "1470904569.py - 17-Feb-2025 21:09:02 - INFO - <module> - Line 74 - Current running loss: 1.0309\n",
      "1470904569.py - 17-Feb-2025 21:09:07 - INFO - <module> - Line 74 - Current running loss: 1.0318\n",
      "1470904569.py - 17-Feb-2025 21:09:11 - INFO - <module> - Line 74 - Current running loss: 1.0356\n",
      "1470904569.py - 17-Feb-2025 21:09:16 - INFO - <module> - Line 74 - Current running loss: 1.0369\n",
      "1470904569.py - 17-Feb-2025 21:09:21 - INFO - <module> - Line 74 - Current running loss: 1.0427\n",
      "1470904569.py - 17-Feb-2025 21:09:25 - INFO - <module> - Line 74 - Current running loss: 1.0462\n",
      "1470904569.py - 17-Feb-2025 21:09:30 - INFO - <module> - Line 74 - Current running loss: 1.0521\n",
      "1470904569.py - 17-Feb-2025 21:09:34 - INFO - <module> - Line 74 - Current running loss: 1.0545\n",
      "1470904569.py - 17-Feb-2025 21:09:39 - INFO - <module> - Line 74 - Current running loss: 1.0577\n",
      "1470904569.py - 17-Feb-2025 21:09:43 - INFO - <module> - Line 74 - Current running loss: 1.0599\n",
      "1470904569.py - 17-Feb-2025 21:09:48 - INFO - <module> - Line 74 - Current running loss: 1.0624\n",
      "1470904569.py - 17-Feb-2025 21:09:52 - INFO - <module> - Line 74 - Current running loss: 1.0661\n",
      "1470904569.py - 17-Feb-2025 21:09:57 - INFO - <module> - Line 74 - Current running loss: 1.0683\n",
      "1470904569.py - 17-Feb-2025 21:10:02 - INFO - <module> - Line 74 - Current running loss: 1.0689\n",
      "1470904569.py - 17-Feb-2025 21:10:06 - INFO - <module> - Line 74 - Current running loss: 1.0717\n",
      "1470904569.py - 17-Feb-2025 21:10:11 - INFO - <module> - Line 74 - Current running loss: 1.0734\n",
      "1470904569.py - 17-Feb-2025 21:10:15 - INFO - <module> - Line 74 - Current running loss: 1.0779\n",
      "1470904569.py - 17-Feb-2025 21:10:20 - INFO - <module> - Line 74 - Current running loss: 1.0785\n",
      "1470904569.py - 17-Feb-2025 21:10:25 - INFO - <module> - Line 74 - Current running loss: 1.0802\n",
      "1470904569.py - 17-Feb-2025 21:10:29 - INFO - <module> - Line 74 - Current running loss: 1.0812\n",
      "1470904569.py - 17-Feb-2025 21:10:34 - INFO - <module> - Line 74 - Current running loss: 1.0820\n",
      "1470904569.py - 17-Feb-2025 21:10:38 - INFO - <module> - Line 74 - Current running loss: 1.0831\n",
      "1470904569.py - 17-Feb-2025 21:10:43 - INFO - <module> - Line 74 - Current running loss: 1.0839\n",
      "1470904569.py - 17-Feb-2025 21:10:47 - INFO - <module> - Line 74 - Current running loss: 1.0862\n",
      "1470904569.py - 17-Feb-2025 21:10:52 - INFO - <module> - Line 74 - Current running loss: 1.0879\n",
      "1470904569.py - 17-Feb-2025 21:10:57 - INFO - <module> - Line 74 - Current running loss: 1.0907\n",
      "1470904569.py - 17-Feb-2025 21:11:01 - INFO - <module> - Line 74 - Current running loss: 1.0928\n",
      "1470904569.py - 17-Feb-2025 21:11:06 - INFO - <module> - Line 74 - Current running loss: 1.0948\n",
      "1470904569.py - 17-Feb-2025 21:11:11 - INFO - <module> - Line 74 - Current running loss: 1.0957\n",
      "1470904569.py - 17-Feb-2025 21:11:15 - INFO - <module> - Line 74 - Current running loss: 1.0983\n",
      "1470904569.py - 17-Feb-2025 21:11:20 - INFO - <module> - Line 74 - Current running loss: 1.1010\n",
      "1470904569.py - 17-Feb-2025 21:11:25 - INFO - <module> - Line 74 - Current running loss: 1.1032\n",
      "1470904569.py - 17-Feb-2025 21:11:29 - INFO - <module> - Line 74 - Current running loss: 1.1052\n",
      "1470904569.py - 17-Feb-2025 21:11:34 - INFO - <module> - Line 74 - Current running loss: 1.1061\n",
      "1470904569.py - 17-Feb-2025 21:11:38 - INFO - <module> - Line 74 - Current running loss: 1.1098\n",
      "1470904569.py - 17-Feb-2025 21:11:43 - INFO - <module> - Line 74 - Current running loss: 1.1118\n",
      "1470904569.py - 17-Feb-2025 21:11:48 - INFO - <module> - Line 74 - Current running loss: 1.1138\n",
      "1470904569.py - 17-Feb-2025 21:11:53 - INFO - <module> - Line 74 - Current running loss: 1.1158\n",
      "1470904569.py - 17-Feb-2025 21:11:58 - INFO - <module> - Line 74 - Current running loss: 1.1186\n",
      "1470904569.py - 17-Feb-2025 21:12:02 - INFO - <module> - Line 74 - Current running loss: 1.1197\n",
      "1470904569.py - 17-Feb-2025 21:12:07 - INFO - <module> - Line 74 - Current running loss: 1.1209\n",
      "1470904569.py - 17-Feb-2025 21:12:12 - INFO - <module> - Line 74 - Current running loss: 1.1219\n",
      "1470904569.py - 17-Feb-2025 21:12:16 - INFO - <module> - Line 74 - Current running loss: 1.1236\n",
      "1470904569.py - 17-Feb-2025 21:12:21 - INFO - <module> - Line 74 - Current running loss: 1.1249\n",
      "1470904569.py - 17-Feb-2025 21:12:26 - INFO - <module> - Line 74 - Current running loss: 1.1271\n",
      "1470904569.py - 17-Feb-2025 21:12:30 - INFO - <module> - Line 74 - Current running loss: 1.1289\n",
      "1470904569.py - 17-Feb-2025 21:12:35 - INFO - <module> - Line 74 - Current running loss: 1.1295\n",
      "1470904569.py - 17-Feb-2025 21:12:39 - INFO - <module> - Line 74 - Current running loss: 1.1304\n",
      "1470904569.py - 17-Feb-2025 21:12:44 - INFO - <module> - Line 74 - Current running loss: 1.1307\n",
      "1470904569.py - 17-Feb-2025 21:12:48 - INFO - <module> - Line 74 - Current running loss: 1.1437\n",
      "1470904569.py - 17-Feb-2025 21:12:53 - INFO - <module> - Line 74 - Current running loss: 1.1460\n",
      "1470904569.py - 17-Feb-2025 21:12:58 - INFO - <module> - Line 74 - Current running loss: 1.1500\n",
      "1470904569.py - 17-Feb-2025 21:13:02 - INFO - <module> - Line 74 - Current running loss: 1.1508\n",
      "1470904569.py - 17-Feb-2025 21:13:07 - INFO - <module> - Line 74 - Current running loss: 1.1637\n",
      "1470904569.py - 17-Feb-2025 21:13:12 - INFO - <module> - Line 74 - Current running loss: 1.1659\n",
      "1470904569.py - 17-Feb-2025 21:13:17 - INFO - <module> - Line 74 - Current running loss: 1.1663\n",
      "1470904569.py - 17-Feb-2025 21:13:21 - INFO - <module> - Line 74 - Current running loss: 1.1691\n",
      "1470904569.py - 17-Feb-2025 21:13:21 - INFO - <module> - Line 24 - Bounding Box Coordinates: 7\n",
      "1470904569.py - 17-Feb-2025 21:13:26 - INFO - <module> - Line 74 - Current running loss: 1.1925\n",
      "1470904569.py - 17-Feb-2025 21:13:30 - INFO - <module> - Line 74 - Current running loss: 1.2118\n",
      "1470904569.py - 17-Feb-2025 21:13:35 - INFO - <module> - Line 74 - Current running loss: 1.2261\n",
      "1470904569.py - 17-Feb-2025 21:13:39 - INFO - <module> - Line 74 - Current running loss: 1.2641\n",
      "1470904569.py - 17-Feb-2025 21:13:44 - INFO - <module> - Line 74 - Current running loss: 1.2854\n",
      "1470904569.py - 17-Feb-2025 21:13:48 - INFO - <module> - Line 74 - Current running loss: 1.3001\n",
      "1470904569.py - 17-Feb-2025 21:13:53 - INFO - <module> - Line 74 - Current running loss: 1.3097\n",
      "1470904569.py - 17-Feb-2025 21:13:53 - INFO - <module> - Line 24 - Bounding Box Coordinates: 53\n",
      "1470904569.py - 17-Feb-2025 21:13:58 - INFO - <module> - Line 74 - Current running loss: 1.3112\n",
      "1470904569.py - 17-Feb-2025 21:14:02 - INFO - <module> - Line 74 - Current running loss: 1.3124\n",
      "1470904569.py - 17-Feb-2025 21:14:07 - INFO - <module> - Line 74 - Current running loss: 1.3129\n",
      "1470904569.py - 17-Feb-2025 21:14:12 - INFO - <module> - Line 74 - Current running loss: 1.3141\n",
      "1470904569.py - 17-Feb-2025 21:14:16 - INFO - <module> - Line 74 - Current running loss: 1.3209\n",
      "1470904569.py - 17-Feb-2025 21:14:21 - INFO - <module> - Line 74 - Current running loss: 1.3224\n",
      "1470904569.py - 17-Feb-2025 21:14:25 - INFO - <module> - Line 74 - Current running loss: 1.3282\n",
      "1470904569.py - 17-Feb-2025 21:14:30 - INFO - <module> - Line 74 - Current running loss: 1.3352\n",
      "1470904569.py - 17-Feb-2025 21:14:35 - INFO - <module> - Line 74 - Current running loss: 1.3395\n",
      "1470904569.py - 17-Feb-2025 21:14:39 - INFO - <module> - Line 74 - Current running loss: 1.3458\n",
      "1470904569.py - 17-Feb-2025 21:14:44 - INFO - <module> - Line 74 - Current running loss: 1.3513\n",
      "1470904569.py - 17-Feb-2025 21:14:48 - INFO - <module> - Line 74 - Current running loss: 1.3554\n",
      "1470904569.py - 17-Feb-2025 21:14:53 - INFO - <module> - Line 74 - Current running loss: 1.3607\n",
      "1470904569.py - 17-Feb-2025 21:14:58 - INFO - <module> - Line 74 - Current running loss: 1.3646\n",
      "1470904569.py - 17-Feb-2025 21:15:02 - INFO - <module> - Line 74 - Current running loss: 1.3672\n",
      "1470904569.py - 17-Feb-2025 21:15:07 - INFO - <module> - Line 74 - Current running loss: 1.3701\n",
      "1470904569.py - 17-Feb-2025 21:15:11 - INFO - <module> - Line 74 - Current running loss: 1.3720\n",
      "1470904569.py - 17-Feb-2025 21:15:16 - INFO - <module> - Line 74 - Current running loss: 1.3727\n",
      "1470904569.py - 17-Feb-2025 21:15:20 - INFO - <module> - Line 74 - Current running loss: 1.3757\n",
      "1470904569.py - 17-Feb-2025 21:15:25 - INFO - <module> - Line 74 - Current running loss: 1.3765\n",
      "1470904569.py - 17-Feb-2025 21:15:30 - INFO - <module> - Line 74 - Current running loss: 1.3771\n",
      "1470904569.py - 17-Feb-2025 21:15:34 - INFO - <module> - Line 74 - Current running loss: 1.3809\n",
      "1470904569.py - 17-Feb-2025 21:15:39 - INFO - <module> - Line 74 - Current running loss: 1.3832\n",
      "1470904569.py - 17-Feb-2025 21:15:43 - INFO - <module> - Line 74 - Current running loss: 1.3880\n",
      "1470904569.py - 17-Feb-2025 21:15:48 - INFO - <module> - Line 74 - Current running loss: 1.3898\n",
      "1470904569.py - 17-Feb-2025 21:15:52 - INFO - <module> - Line 74 - Current running loss: 1.3932\n",
      "1470904569.py - 17-Feb-2025 21:15:57 - INFO - <module> - Line 74 - Current running loss: 1.3939\n",
      "1470904569.py - 17-Feb-2025 21:16:02 - INFO - <module> - Line 74 - Current running loss: 1.3975\n",
      "1470904569.py - 17-Feb-2025 21:16:06 - INFO - <module> - Line 74 - Current running loss: 1.3983\n",
      "1470904569.py - 17-Feb-2025 21:16:11 - INFO - <module> - Line 74 - Current running loss: 1.3991\n",
      "1470904569.py - 17-Feb-2025 21:16:15 - INFO - <module> - Line 74 - Current running loss: 1.3997\n",
      "1470904569.py - 17-Feb-2025 21:16:20 - INFO - <module> - Line 74 - Current running loss: 1.4015\n",
      "1470904569.py - 17-Feb-2025 21:16:25 - INFO - <module> - Line 74 - Current running loss: 1.4025\n",
      "1470904569.py - 17-Feb-2025 21:16:29 - INFO - <module> - Line 74 - Current running loss: 1.4049\n",
      "1470904569.py - 17-Feb-2025 21:16:34 - INFO - <module> - Line 74 - Current running loss: 1.4076\n",
      "1470904569.py - 17-Feb-2025 21:16:39 - INFO - <module> - Line 74 - Current running loss: 1.4091\n",
      "1470904569.py - 17-Feb-2025 21:16:44 - INFO - <module> - Line 74 - Current running loss: 1.4124\n",
      "1470904569.py - 17-Feb-2025 21:16:48 - INFO - <module> - Line 74 - Current running loss: 1.4171\n",
      "1470904569.py - 17-Feb-2025 21:16:53 - INFO - <module> - Line 74 - Current running loss: 1.4177\n",
      "1470904569.py - 17-Feb-2025 21:16:57 - INFO - <module> - Line 74 - Current running loss: 1.4262\n",
      "1470904569.py - 17-Feb-2025 21:17:02 - INFO - <module> - Line 74 - Current running loss: 1.4273\n",
      "1470904569.py - 17-Feb-2025 21:17:06 - INFO - <module> - Line 74 - Current running loss: 1.4288\n",
      "1470904569.py - 17-Feb-2025 21:17:11 - INFO - <module> - Line 74 - Current running loss: 1.4294\n",
      "1470904569.py - 17-Feb-2025 21:17:16 - INFO - <module> - Line 74 - Current running loss: 1.4324\n",
      "1470904569.py - 17-Feb-2025 21:17:20 - INFO - <module> - Line 74 - Current running loss: 1.4373\n",
      "1470904569.py - 17-Feb-2025 21:17:25 - INFO - <module> - Line 74 - Current running loss: 1.4396\n",
      "1470904569.py - 17-Feb-2025 21:17:30 - INFO - <module> - Line 74 - Current running loss: 1.4413\n",
      "1470904569.py - 17-Feb-2025 21:17:34 - INFO - <module> - Line 74 - Current running loss: 1.4463\n",
      "1470904569.py - 17-Feb-2025 21:17:39 - INFO - <module> - Line 74 - Current running loss: 1.4473\n",
      "1470904569.py - 17-Feb-2025 21:17:43 - INFO - <module> - Line 74 - Current running loss: 1.4492\n",
      "1470904569.py - 17-Feb-2025 21:17:48 - INFO - <module> - Line 74 - Current running loss: 1.4522\n",
      "1470904569.py - 17-Feb-2025 21:17:53 - INFO - <module> - Line 74 - Current running loss: 1.4533\n",
      "1470904569.py - 17-Feb-2025 21:17:57 - INFO - <module> - Line 74 - Current running loss: 1.4545\n",
      "1470904569.py - 17-Feb-2025 21:17:57 - INFO - <module> - Line 87 - Epoch 1 completed. Loss: 0.2909\n",
      "1470904569.py - 17-Feb-2025 21:17:57 - INFO - <module> - Line 5 - Epoch 2/20 started\n",
      "1470904569.py - 17-Feb-2025 21:17:57 - INFO - <module> - Line 24 - Bounding Box Coordinates: 4\n",
      "1470904569.py - 17-Feb-2025 21:18:02 - INFO - <module> - Line 74 - Current running loss: 0.0093\n",
      "1470904569.py - 17-Feb-2025 21:18:07 - INFO - <module> - Line 74 - Current running loss: 0.0357\n",
      "1470904569.py - 17-Feb-2025 21:18:12 - INFO - <module> - Line 74 - Current running loss: 0.0674\n",
      "1470904569.py - 17-Feb-2025 21:18:16 - INFO - <module> - Line 74 - Current running loss: 0.0959\n",
      "1470904569.py - 17-Feb-2025 21:18:16 - INFO - <module> - Line 24 - Bounding Box Coordinates: 53\n",
      "1470904569.py - 17-Feb-2025 21:18:21 - INFO - <module> - Line 74 - Current running loss: 0.0984\n",
      "1470904569.py - 17-Feb-2025 21:18:25 - INFO - <module> - Line 74 - Current running loss: 0.0996\n",
      "1470904569.py - 17-Feb-2025 21:18:30 - INFO - <module> - Line 74 - Current running loss: 0.0998\n",
      "1470904569.py - 17-Feb-2025 21:18:34 - INFO - <module> - Line 74 - Current running loss: 0.1007\n",
      "1470904569.py - 17-Feb-2025 21:18:39 - INFO - <module> - Line 74 - Current running loss: 0.1055\n",
      "1470904569.py - 17-Feb-2025 21:18:43 - INFO - <module> - Line 74 - Current running loss: 0.1064\n",
      "1470904569.py - 17-Feb-2025 21:18:48 - INFO - <module> - Line 74 - Current running loss: 0.1113\n",
      "1470904569.py - 17-Feb-2025 21:18:53 - INFO - <module> - Line 74 - Current running loss: 0.1180\n",
      "1470904569.py - 17-Feb-2025 21:18:57 - INFO - <module> - Line 74 - Current running loss: 0.1208\n",
      "1470904569.py - 17-Feb-2025 21:19:02 - INFO - <module> - Line 74 - Current running loss: 0.1271\n",
      "1470904569.py - 17-Feb-2025 21:19:07 - INFO - <module> - Line 74 - Current running loss: 0.1292\n",
      "1470904569.py - 17-Feb-2025 21:19:12 - INFO - <module> - Line 74 - Current running loss: 0.1332\n",
      "1470904569.py - 17-Feb-2025 21:19:16 - INFO - <module> - Line 74 - Current running loss: 0.1386\n",
      "1470904569.py - 17-Feb-2025 21:19:21 - INFO - <module> - Line 74 - Current running loss: 0.1416\n",
      "1470904569.py - 17-Feb-2025 21:19:25 - INFO - <module> - Line 74 - Current running loss: 0.1436\n",
      "1470904569.py - 17-Feb-2025 21:19:30 - INFO - <module> - Line 74 - Current running loss: 0.1459\n",
      "1470904569.py - 17-Feb-2025 21:19:35 - INFO - <module> - Line 74 - Current running loss: 0.1479\n",
      "1470904569.py - 17-Feb-2025 21:19:39 - INFO - <module> - Line 74 - Current running loss: 0.1485\n",
      "1470904569.py - 17-Feb-2025 21:19:44 - INFO - <module> - Line 74 - Current running loss: 0.1518\n",
      "1470904569.py - 17-Feb-2025 21:19:49 - INFO - <module> - Line 74 - Current running loss: 0.1525\n",
      "1470904569.py - 17-Feb-2025 21:19:53 - INFO - <module> - Line 74 - Current running loss: 0.1529\n",
      "1470904569.py - 17-Feb-2025 21:19:58 - INFO - <module> - Line 74 - Current running loss: 0.1559\n",
      "1470904569.py - 17-Feb-2025 21:20:03 - INFO - <module> - Line 74 - Current running loss: 0.1580\n",
      "1470904569.py - 17-Feb-2025 21:20:07 - INFO - <module> - Line 74 - Current running loss: 0.1628\n",
      "1470904569.py - 17-Feb-2025 21:20:12 - INFO - <module> - Line 74 - Current running loss: 0.1640\n",
      "1470904569.py - 17-Feb-2025 21:20:16 - INFO - <module> - Line 74 - Current running loss: 0.1671\n",
      "1470904569.py - 17-Feb-2025 21:20:21 - INFO - <module> - Line 74 - Current running loss: 0.1678\n",
      "1470904569.py - 17-Feb-2025 21:20:26 - INFO - <module> - Line 74 - Current running loss: 0.1712\n",
      "1470904569.py - 17-Feb-2025 21:20:31 - INFO - <module> - Line 74 - Current running loss: 0.1720\n",
      "1470904569.py - 17-Feb-2025 21:20:35 - INFO - <module> - Line 74 - Current running loss: 0.1728\n",
      "1470904569.py - 17-Feb-2025 21:20:40 - INFO - <module> - Line 74 - Current running loss: 0.1733\n",
      "1470904569.py - 17-Feb-2025 21:20:45 - INFO - <module> - Line 74 - Current running loss: 0.1748\n",
      "1470904569.py - 17-Feb-2025 21:20:49 - INFO - <module> - Line 74 - Current running loss: 0.1758\n",
      "1470904569.py - 17-Feb-2025 21:20:54 - INFO - <module> - Line 74 - Current running loss: 0.1780\n",
      "1470904569.py - 17-Feb-2025 21:20:59 - INFO - <module> - Line 74 - Current running loss: 0.1808\n",
      "1470904569.py - 17-Feb-2025 21:21:03 - INFO - <module> - Line 74 - Current running loss: 0.1825\n",
      "1470904569.py - 17-Feb-2025 21:21:08 - INFO - <module> - Line 74 - Current running loss: 0.1905\n",
      "1470904569.py - 17-Feb-2025 21:21:12 - INFO - <module> - Line 74 - Current running loss: 0.1991\n"
     ]
    }
   ],
   "source": [
    "sam_logger.info(\"Training Started\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model\n",
    "    sam_logger.info(f\"Epoch {epoch+1}/{num_epochs} started\")\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for img, mask in data_loader:\n",
    "        image_ = img.to(device)\n",
    "        mask_ = mask.to(device)\n",
    "        # sam_logger.debug(f\"images size : {image_.shape}, masks size : {mask_.shape}\")\n",
    "\n",
    "        for (image, mask) in zip(image_, mask_):\n",
    "            \n",
    "            # print(image.shape, mask.shape)\n",
    "\n",
    "            ## getting the bounding box coordinates from masks \n",
    "            # print(mask.numpy())\n",
    "            ## here we have to pass numpy array\n",
    "            # print(mask.numpy().astype(np.uint8))\n",
    "            \n",
    "            bounding_box_corr = bounding_box(mask.detach().cpu().numpy().astype(np.uint8))\n",
    "            sam_logger.info(f\"Bounding Box Coordinates: {len(bounding_box_corr)}\")\n",
    "\n",
    "            # print(bounding_box_corr)\n",
    "\n",
    "\n",
    "            for coordinates in bounding_box_corr:\n",
    "                # print(f\"points are : {coordinates}\")\n",
    "                one_isolated_mask = generate_isolated_mask(mask, coordinates)\n",
    "                one_isolated_mask = one_isolated_mask.unsqueeze(0)\n",
    "                one_isolated_mask = one_isolated_mask/255.0\n",
    "                # print(f\"Unique values of isolated masks are : \",torch.unique(one_isolated_mask))\n",
    "                # print(\"isolated mask shape : \",one_isolated_mask.shape)\n",
    "                \n",
    "                # plt.imshow(one_isolated_mask.squeeze(0).numpy(), cmap=\"gray\")\n",
    "                # plt.show()\n",
    "                \n",
    "                \n",
    "                sparse_embeddings, dense_embeddings = model.prompt_encoder(\n",
    "                    points = None,\n",
    "                    boxes = torch.tensor([coordinates]).unsqueeze(0).to(device),masks = None)\n",
    "                \n",
    "                low_res_mask, _ = model.mask_decoder(\n",
    "                    image_embeddings = model.image_encoder(image.unsqueeze(0)),\n",
    "                    image_pe = model.prompt_encoder.get_dense_pe(),\n",
    "                    sparse_prompt_embeddings = sparse_embeddings,\n",
    "                    dense_prompt_embeddings = dense_embeddings,\n",
    "                    multimask_output = False\n",
    "                )\n",
    "\n",
    "                upsampled_masks = F.interpolate(low_res_mask, size = (1024, 1024), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "                ## calculate the loss\n",
    "                # print(\"Upsampled mask shape : \",upsampled_masks.shape)\n",
    "                # print(\"Unique values this tensor contain is : \", torch.unique(upsampled_masks))\n",
    "                \n",
    "                # print(upsampled_masks)\n",
    "                loss = seg_loss(upsampled_masks, one_isolated_mask.unsqueeze(0).float())\n",
    "                \n",
    "                # backward pass (compute gradients of parameters w.r.t. loss)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                # Optimize\n",
    "                optimizer.step()\n",
    "                \n",
    "                if len(bounding_box_corr) > 0:\n",
    "                    running_loss += loss.item() / len(bounding_box_corr)\n",
    "                \n",
    "                # print(f\"runing loss: {running_loss}\")\n",
    "                sam_logger.info(f\"Current running loss: {running_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "                # to see the output and actual masks\n",
    "                # copy_up_sampled = upsampled_masks.clone()\n",
    "\n",
    "                # plt.imshow(copy_up_sampled.squeeze(0).squeeze(0).detach().numpy(),cmap=\"gray\")\n",
    "                # plt.tight_layout()\n",
    "                # plt.show()\n",
    "\n",
    "    \n",
    "    # print(f\"epoch {epoch}, loss: {running_loss / len(data_loader)}\")\n",
    "    sam_logger.info(f\"Epoch {epoch+1} completed. Loss: {running_loss / len(data_loader):.4f}\")\n",
    "    \n",
    "    early_stopping(running_loss, model, epoch)\n",
    "    if early_stopping.early_stop:\n",
    "        sam_logger.error(f\"Early Stoping : Epoch {epoch+1} completed. Loss: {running_loss / len(data_loader):.4f}\")\n",
    "        sam_logger.error(f\"TRAINING STOPPED EARLY\")\n",
    "        break  # Stop training if early stopping is triggered\n",
    "\n",
    "    \n",
    "    \n",
    "    ## save the model checkpoint every 10 epoch\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        current_date = datetime.datetime.now().strftime(\"%d_%m_%Y\")\n",
    "        os.makedirs(checkpoint, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(checkpoint, f\"sam_model_{epoch + 1}_{current_date}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        sam_logger.info(f\"Model checkpoint saved at {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_checkpoint = \"checkpoints/Final_Models\"\n",
    "os.makedirs(checkpoint, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = f\"images_{len(images)}_epoch_{num_epochs}_\"+datetime.datetime.now().strftime(\"%d_%m_%Y\")+\".pth\"\n",
    "final_model_path = os.path.join(final_model_checkpoint, current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
